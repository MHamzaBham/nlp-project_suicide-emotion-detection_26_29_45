{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2SjvjPAtCbP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(\"wordnet\", quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q09CooGutQCk"
      },
      "outputs": [],
      "source": [
        "# CONFIG\n",
        "DATA_PATH = \"data/Suicide_Detection.csv\"\n",
        "MODELS_DIR = \"models\"\n",
        "TOKENIZER_PATH = os.path.join(MODELS_DIR, \"tokenizer.json\")\n",
        "MODEL_PATH = os.path.join(MODELS_DIR, \"suicide_model.keras\")\n",
        "TEMP_MODEL_PATH = os.path.join(MODELS_DIR, \"suicide_model_tmp.keras\")\n",
        "\n",
        "MAX_NUM_WORDS = 20000\n",
        "MAX_SEQUENCE_LENGTH = 200\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(\"static\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvgOI9OqtnEg"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "contraction_map = {\n",
        "    \"i'm\": \"i am\", \"ain't\": \"is not\", \"can't\": \"can not\",\n",
        "    \"won't\": \"will not\", \"i've\": \"i have\", \"i'll\": \"i will\",\n",
        "    \"you're\": \"you are\", \"they're\": \"they are\", \"we're\": \"we are\",\n",
        "    \"it's\": \"it is\", \"that's\": \"that is\"\n",
        "}\n",
        "\n",
        "slang_map = {\n",
        "    \"gonna\": \"going to\", \"wanna\": \"want to\", \"idk\": \"i do not know\",\n",
        "    \"lol\": \"\", \"lmao\": \"\", \"pls\": \"please\"\n",
        "}\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def expand_contractions_and_slang(text):\n",
        "    t = text.lower()\n",
        "    for k, v in contraction_map.items():\n",
        "        t = re.sub(r'\\b' + re.escape(k) + r'\\b', v, t)\n",
        "    for k, v in slang_map.items():\n",
        "        t = re.sub(r'\\b' + re.escape(k) + r'\\b', v, t)\n",
        "    return t\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    t = text.strip()\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = expand_contractions_and_slang(t)\n",
        "    t = t.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\")\n",
        "    t = re.sub(r\"[^a-zA-Z\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "    words = [lemmatizer.lemmatize(w) for w in t.split()]\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKLNVQw5ty77"
      },
      "outputs": [],
      "source": [
        "# LOAD DATA\n",
        "print(\"Loading dataset:\", DATA_PATH)\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# auto-detect columns\n",
        "if \"text\" not in df.columns:\n",
        "    candidates = [c for c in df.columns if \"text\" in c.lower()]\n",
        "    if candidates:\n",
        "        df.rename(columns={candidates[0]: \"text\"}, inplace=True)\n",
        "    else:\n",
        "        raise ValueError(\"No 'text' column found.\")\n",
        "\n",
        "if \"class\" not in df.columns:\n",
        "    candidates = [c for c in df.columns if \"class\" in c.lower() or \"label\" in c.lower()]\n",
        "    if candidates:\n",
        "        df.rename(columns={candidates[0]: \"class\"}, inplace=True)\n",
        "    else:\n",
        "        raise ValueError(\"No label column.\")\n",
        "\n",
        "df.dropna(subset=[\"text\", \"class\"], inplace=True)\n",
        "\n",
        "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
        "df = df[df[\"clean_text\"].str.strip() != \"\"]\n",
        "\n",
        "label_map = {\"suicide\": 1, \"non-suicide\": 0}\n",
        "df[\"label\"] = df[\"class\"].astype(str).str.lower().map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vyGKNxXt7oZ"
      },
      "outputs": [],
      "source": [
        "# Tokenizer\n",
        "if os.path.exists(TOKENIZER_PATH):\n",
        "    print(\"Loading tokenizer...\")\n",
        "    with open(TOKENIZER_PATH, \"r\") as f:\n",
        "        tokenizer = tokenizer_from_json(f.read())\n",
        "else:\n",
        "    print(\"Training tokenizer...\")\n",
        "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(df[\"clean_text\"])\n",
        "    with open(TOKENIZER_PATH, \"w\") as f:\n",
        "        f.write(tokenizer.to_json())\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df[\"clean_text\"])\n",
        "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y = df[\"label\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP9c9xH4uPQE"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# class weight\n",
        "counts = Counter(y_train)\n",
        "total = sum(counts.values())\n",
        "class_weight = {c: total / (len(counts) * n) for c, n in counts.items()}\n",
        "\n",
        "# Model\n",
        "vocab_size = min(MAX_NUM_WORDS, len(tokenizer.word_index) + 1)\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
        "        Conv1D(128, 5, activation=\"relu\"),\n",
        "        MaxPooling1D(4),\n",
        "        Dropout(0.4),\n",
        "        Bidirectional(LSTM(64, dropout=0.3)),\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(0.01)),\n",
        "    ])\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Load or train\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    print(\"Loading saved model...\")\n",
        "    model = load_model(MODEL_PATH)\n",
        "    history = None\n",
        "else:\n",
        "    print(\"Training new model...\")\n",
        "    model = build_model()\n",
        "\n",
        "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2)\n",
        "    checkpoint = ModelCheckpoint(TEMP_MODEL_PATH, save_best_only=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "        class_weight=class_weight,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    if os.path.exists(TEMP_MODEL_PATH):\n",
        "        os.replace(TEMP_MODEL_PATH, MODEL_PATH)\n",
        "    else:\n",
        "        model.save(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvFGvotKuXdm"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "y_prob = model.predict(X_test).ravel()\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "\n",
        "best_idx = np.argmax(tpr - fpr)\n",
        "best_thresh = thresholds[best_idx]\n",
        "\n",
        "y_pred = (y_prob >= best_thresh).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n----- MODEL PERFORMANCE -----\")\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall:\", rec)\n",
        "print(\"F1:\", f1)\n",
        "print(\"AUC:\", auc)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.bar([\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"], [acc, prec, rec, f1, auc])\n",
        "plt.title(\"Metrics\")\n",
        "plt.ylim(0, 1)\n",
        "plt.savefig(\"static/metrics.png\")\n",
        "plt.show()\n",
        "\n",
        "if history:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"Val\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Val\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"static/training_curves.png\")\n",
        "    plt.show()\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure()\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(\"static/confusion_matrix.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYHwwnGnufHg"
      },
      "outputs": [],
      "source": [
        "# Text\n",
        "def predict_texts(texts):\n",
        "    cleaned = [clean_text(t) for t in texts]\n",
        "    seqs = tokenizer.texts_to_sequences(cleaned)\n",
        "    pad = pad_sequences(seqs, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    probs = model.predict(pad).ravel()\n",
        "    return [(t, int(p >= best_thresh), float(p)) for t, p in zip(cleaned, probs)]\n",
        "\n",
        "# quick test\n",
        "examples = [\"I want to die\", \"Life is beautiful\", \"I feel like killing myself\"]\n",
        "print(\"\\n--- TEST PREDICTIONS ---\")\n",
        "for txt, lbl, prob in predict_texts(examples):\n",
        "    print(f\"{txt} â†’ label={lbl}, prob={prob}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
